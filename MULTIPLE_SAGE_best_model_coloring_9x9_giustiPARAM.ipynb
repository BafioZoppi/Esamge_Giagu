{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BafioZoppi/Esamge_Giagu/blob/main/MULTIPLE_SAGE_best_model_coloring_9x9_giustiPARAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "final-field"
      },
      "source": [
        "# Graph Coloring with Physics-Inspired Graph Neural Networks(SAGE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rp2HKd3see2",
        "outputId": "67755919-4f8a-4be0-e907-dc6ef5c564b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.0+cu121\n",
            "0.20.0+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)\n",
        "import os.path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import warnings\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from time import time"
      ],
      "metadata": {
        "id": "xu48cm-Jtgkt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qquVSysttguE",
        "outputId": "0ec4059a-a081-4fae-cae8-1063f5821066"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import torch_geometric\n",
        "except ImportError:\n",
        "    !pip install torch_geometric\n",
        "    import torch_geometric"
      ],
      "metadata": {
        "id": "QeGl4p91tk83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bdcdfac7-24e5-4bb3-b9fa-281cbef00b4f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch_geometric) (0.2.0)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3070, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2863, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 247, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2786, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3072, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3082, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3146, in __init__\n",
            "    str(self.marker) if self.marker else None,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/markers.py\", line 287, in __str__\n",
            "    return _format_marker(self._markers)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/markers.py\", line 147, in _format_marker\n",
            "    isinstance(marker, list)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 216, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1465, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 686, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 636, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 119, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 502, in __init__\n",
            "    self.stack = StackSummary.extract(\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 383, in extract\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 306, in line\n",
            "    self._line = linecache.getline(self.filename, self.lineno)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 30, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 46, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 136, in updatecache\n",
            "    with tokenize.open(fullname) as fp:\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 396, in open\n",
            "    encoding, lines = detect_encoding(buffer.readline)\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 365, in detect_encoding\n",
            "    first = read_or_stop()\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 323, in read_or_stop\n",
            "    return readline()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch_geometric'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-82c0e1872dc6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-82c0e1872dc6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install torch_geometric'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import SAGEConv, GCNConv\n",
        "from itertools import chain"
      ],
      "metadata": {
        "id": "-T3xRE9Ttk__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define device to use (cpu/gpu)\n",
        "if torch.cuda.is_available():\n",
        "  print('# of GPUs available: ', torch.cuda.device_count())\n",
        "  print('First GPU type: ',torch.cuda.get_device_name(0))\n",
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Computation device: {device}\\n\")"
      ],
      "metadata": {
        "id": "St0YDpyXtlDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED_VALUE = 0           #lo richiamo anche sotto per get_gnn\n",
        "random.seed(SEED_VALUE)        # seed python RNG\n",
        "np.random.seed(SEED_VALUE)     # seed global NumPy RNG\n",
        "torch.manual_seed(SEED_VALUE)  # seed torch RNG\n",
        "\n",
        "# Set GPU/CPU\n",
        "TORCH_DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "TORCH_DTYPE = torch.float32\n",
        "print(f'Will use device: {TORCH_DEVICE}, torch dtype: {TORCH_DTYPE}')"
      ],
      "metadata": {
        "id": "ixhV8-LTe2d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/FEDECOLOR"
      ],
      "metadata": {
        "id": "Ln4MrzU7e5Vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "Wh3_DgIavJVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Known chromatic numbers for specified problems (from references)\n",
        "chromatic_numbers = {\n",
        "    # COLOR graphs\n",
        "    'jean.col': 10,\n",
        "    'anna.col': 11,\n",
        "    'huck.col': 11,\n",
        "    'david.col': 11,\n",
        "    'homer.col': 13,\n",
        "    'myciel5.col': 6,\n",
        "    'myciel6.col': 7,\n",
        "    'queen5_5.col': 5,\n",
        "    'queen6_6.col': 7,\n",
        "    'queen7_7.col': 7,\n",
        "    'queen8_8.col': 9,\n",
        "    'queen9_9.col': 10,\n",
        "    'queen8_12.col': 12,\n",
        "    'queen11_11.col': 11,\n",
        "    'queen13_13.col': 13,\n",
        "    # Citations graphs\n",
        "    'cora.cites': 5,\n",
        "    'citeseer.cites': 6,\n",
        "    'pubmed.cites': 8\n",
        "}"
      ],
      "metadata": {
        "id": "RCXzFolefNsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FACCIO FUNZIONE CHE SALVA BEST MODELLO COSI NON DEVO CAMBIARE SOTTO IL NOME DEL FILE\n",
        "def save_model(model,path, best_cost, best_loss, epoch):\n",
        "    torch.save(model.state_dict(), path)                    #aggiunto stasera\n",
        "    print(f'Model saved with best_cost: {best_cost:.1f}  and best_loss(soft loss): {best_loss:.4f} at the epoch: {epoch}')"
      ],
      "metadata": {
        "id": "CChs31kxBnU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DOVCITglBndS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#funzione per cambiare il seme nel train\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Sets random seeds for training.\n",
        "\n",
        "    :param seed: Integer used for seed.\n",
        "    :type seed: int\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)"
      ],
      "metadata": {
        "id": "HCh7R5xNfakz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_adjacency_matrix(nx_graph, torch_device, torch_dtype):\n",
        "    \"\"\"\n",
        "    Pre-load adjacency matrix, map to torch device\n",
        "\n",
        "    :param nx_graph: Graph object to pull adjacency matrix for\n",
        "    :type nx_graph: networkx.OrderedGraph   per me cambiato con DiGraph/Graph\n",
        "    :param torch_device: Compute device to map computations onto (CPU vs GPU)\n",
        "    :type torch_dtype: str\n",
        "    :param torch_dtype: Specification of pytorch datatype to use for matrix\n",
        "    :type torch_dtype: str\n",
        "    :return: Adjacency matrix for provided graph\n",
        "    :rtype: torch.tensor\n",
        "    \"\"\"\n",
        "\n",
        "    adj = nx.linalg.graphmatrix.adjacency_matrix(nx_graph).todense()\n",
        "    adj_ = torch.tensor(adj).type(torch_dtype).to(torch_device)\n",
        "\n",
        "    return adj_"
      ],
      "metadata": {
        "id": "NNpOcRjdfarc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_line(file_line, node_offset):\n",
        "    \"\"\"\n",
        "    Helper function to parse lines out of COLOR files - skips first character, which\n",
        "    will be an \"e\" to denote an edge definition, and returns node0, node1 that define\n",
        "    the edge in the line.\n",
        "\n",
        "    :param file_line: Line to be parsed\n",
        "    :type file_line: str\n",
        "    :param node_offset: How much to add to account for file numbering (i.e. offset by 1)\n",
        "    :type node_offset: int\n",
        "    :return: Set of nodes connected by edge defined in the line (i.e. node_from, node_to)\n",
        "    :rtype: int, int\n",
        "    \"\"\"\n",
        "\n",
        "    x, y = file_line.split(' ')[1:]  # skip first character - specifies each line is an edge definition\n",
        "    x, y = int(x)+node_offset, int(y)+node_offset  # nodes in file are 1-indexed, whereas python is 0-indexed (NON PENSO SIA QUESTO IL PROBLEMA)\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "m1RUhQVWflR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_graph_from_color_file(fname, node_offset=-1, parent_fpath=''):               #sta tutto qua come creo grafico\n",
        "    \"\"\"\n",
        "    Load problem definition (graph) from COLOR file (e.g. *.col).\n",
        "\n",
        "    :param fname: Filename of COLOR file\n",
        "    :type fname: str\n",
        "    :param node_offset: How much to offset node values contained in file\n",
        "    :type node_offset: int\n",
        "    :param parent_fpath: Path to prepend to `fname`\n",
        "    :type parent_fpath: str\n",
        "    :return: Graph defined in provided file\n",
        "    :rtype: networkx.OrderedGraph === CAMBIATO con network.DiGraph\n",
        "    \"\"\"\n",
        "\n",
        "    fpath = os.path.join(parent_fpath, fname)\n",
        "\n",
        "    print(f'Building graph from contents of file: {fpath}')\n",
        "    with open(fpath, 'r') as f:\n",
        "        content = f.read().strip()\n",
        "\n",
        "    # Identify where problem definition starts.\n",
        "    # All lines prior to this are assumed to be miscellaneous descriptions of file contents\n",
        "    # which start with \"c = p\".\n",
        "    start_idx = [idx for idx, line in enumerate(content.split('\\n')) if line.startswith('p')][0]\n",
        "    lines = content.split('\\n')[start_idx:]  # skip comment line(s)\n",
        "    edges = [parse_line(line, node_offset) for line in lines[1:] if len(line) > 0]\n",
        "\n",
        "    nx_temp = nx.from_edgelist(edges)\n",
        "\n",
        "    nx_graph = nx.Graph()    #QUESTO É TUTTO, se metto DiGraph é grafo DIRETTO, sennó Undirect concettualmente é piu giusto\n",
        "    nx_graph.add_nodes_from(sorted(nx_temp.nodes()))    #qua mi sa leva i link doppi, ma quando creo torch tensor non lo fa\n",
        "    nx_graph.add_edges_from(nx_temp.edges)\n",
        "\n",
        "    return nx_graph"
      ],
      "metadata": {
        "id": "3AAIOdr9flVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "distinct-batch"
      },
      "source": [
        "# Step 1 - Set hyperparameters - Devo cambiare solo qua(NB solvey_hypers in realtá li ridefinisco sotto nel train ma tanto so sempre uguali)\n",
        "\n",
        "We provide a default set of model hypers. Feel free to modify these as desired.\n",
        "\n",
        "We also include general parameters such as tolerance and patience for early stopping, the layer aggregation specification (`layer_agg_type`) for GraphSAGE, and some tracking of problem definition (problem name, chromatic number)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the problem instance to solve and where to find the dataset(s) here:\n",
        "\n",
        "problem_file = 'queen9_9.col'     #tipo prima era 'queen5_5.col'    #RICORDA DI CAMBIARE IL FILE IN CUI METTI IL BEST MODELLO\n",
        "\n",
        "save_model_path = 'SAGE_best_model_coloring_9X9.pth'   #se cambio problem file, devo cambare anche il nome del file dove salvo il modello addestrato\n",
        "\n",
        "input_parent = './data/input/COLOR/instances'"
      ],
      "metadata": {
        "id": "4BlJfAFIfsBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample hyperparameters\n",
        "hypers = {\n",
        "        'model': 'SAGEConv',   # set either with GNN. It cannot take other input (lo metto dopo)      #sono quelli di GCN conv\n",
        "        'dim_embedding': 109,\n",
        "        'dropout': 0.3257,   #simile a quello di anna\n",
        "        'learning_rate':    0.02636,\n",
        "        'hidden_dim': 16,\n",
        "        'seed': SEED_VALUE\n",
        "    }\n",
        "\n",
        "\n",
        "# Default meta parameters\n",
        "solver_hypers = {\n",
        "    'tolerance': 1e-3,           # Loss must change by more than tolerance, or add towards patience count\n",
        "    'number_epochs': int(5e4),   # Max number training steps   #non lo cambio da qui\n",
        "    'patience': 500,             # Number early stopping triggers before breaking loop #non lo cambio da qui\n",
        "    'graph_file': problem_file,  # Which problem is being solved\n",
        "    'layer_agg_type': 'mean',    # How aggregate neighbors sampled within graphSAGE\n",
        "    'number_classes': chromatic_numbers[problem_file]\n",
        "}\n",
        "\n",
        "# Combine into a single set\n",
        "hypers.update(solver_hypers)"
      ],
      "metadata": {
        "id": "tkG5CHxJfsEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "metric-bathroom"
      },
      "source": [
        "# Step 2 - Load in problem and create graph\n",
        "\n",
        "Load in problem definition from specified path. Variables `input_parent` and `problem_file` should be defined appropriately in cell 3."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.utils import from_networkx"
      ],
      "metadata": {
        "id": "1zjvFO5ZfsH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establish full input location\n",
        "input_fpath = os.path.join(input_parent, problem_file)\n",
        "\n",
        "# Load in graph\n",
        "nx_graph = build_graph_from_color_file(input_fpath, node_offset=-1, parent_fpath='')\n",
        "\n",
        "# Get DGL graph from networkx graph\n",
        "# Ensure relevant objects are placed onto proper torch device\n",
        "torchgeom_graph = from_networkx(nx_graph)\n",
        "torchgeom_graph = torchgeom_graph.to(TORCH_DEVICE)"
      ],
      "metadata": {
        "id": "y0K88xRgfsK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('torchgeom_graf=',torchgeom_graph)    #oh ok\n",
        "print(torchgeom_graph.num_nodes)\n",
        "print(torchgeom_graph.edge_index)"
      ],
      "metadata": {
        "id": "vlydCKjkfsNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize graph\n",
        "pos = nx.kamada_kawai_layout(nx_graph)\n",
        "nx.draw(nx_graph, pos, with_labels=True, node_color=[[.7, .7, .7]])"
      ],
      "metadata": {
        "id": "aC2-EkIlXbM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creo classe della mia GNN\n",
        "\n",
        "\n",
        "class GraphSAGE(nn.Module):\n",
        "    \"\"\"\n",
        "    Basic GraphConv-based GNN class object. Constructs the model architecture upon\n",
        "    initialization. Defines a forward step to include relevant parameters - in this\n",
        "    case, just dropout.\n",
        "    \"\"\"\n",
        "                            #self é la sua roba, g é torchgeom_graph\n",
        "    def __init__(self, g, in_feats, hidden_size, num_classes, dropout):   #le in_feats diventano dim_embedding, hidden size e num_classes é da hypers\n",
        "        \"\"\"\n",
        "        Initialize the model object. Establishes model architecture and relevant hypers (`dropout`, `num_classes`, `agg_type`)\n",
        "\n",
        "        :param g: Input graph object\n",
        "        :type g: Data of torch geometric\n",
        "        :param in_feats: Size (number of nodes) of input layer\n",
        "        :type in_feats: int\n",
        "        :param hidden_size: Size of hidden layer\n",
        "        :type hidden_size: int\n",
        "        :param num_classes: Size of output layer (one node per class)\n",
        "        :type num_classes: int\n",
        "        :param dropout: Dropout fraction, between two convolutional layers\n",
        "        :type dropout: float\n",
        "        \"\"\"\n",
        "\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.g = g\n",
        "        self.conv1 = SAGEConv(in_feats, hidden_size)\n",
        "        self.relu=nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.conv2 = SAGEConv(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, g):\n",
        "        \"\"\"\n",
        "        Define forward step of netowrk. In this example, pass inputs through convolution, apply relu\n",
        "        and dropout, then pass through second convolution.\n",
        "\n",
        "        :param features: Input node representations\n",
        "        :type features: torch.tensor\n",
        "        :return: Final layer representation, pre-activation (i.e. class logits)\n",
        "        :rtype: torch.tensor\"\"\"\n",
        "\n",
        "        x, edge_index = g.x, g.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x"
      ],
      "metadata": {
        "id": "rXwKohwJfsQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torchgeom_graph)"
      ],
      "metadata": {
        "id": "Tb5UUvxHfsVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim_embedding = hypers['dim_embedding']\n",
        "hidden_dim = hypers['hidden_dim']\n",
        "dropout = hypers['dropout']\n",
        "number_classes = hypers['number_classes']\n",
        "agg_type = hypers['layer_agg_type'] or 'mean'\n",
        "model=hypers['model']\n",
        "print(model)"
      ],
      "metadata": {
        "id": "JYGeR0QgfsYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(hidden_dim)"
      ],
      "metadata": {
        "id": "SOBkTkLFfsTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed = nn.Embedding(torchgeom_graph.num_nodes, dim_embedding)    #sto creando matrice  #sarebbero le in_feat ==  dim_embedding, creo #copie di valori dei nodi pari a dim_embedding\n",
        "embed = embed.type(TORCH_DTYPE).to(TORCH_DEVICE)\n",
        "print(embed)"
      ],
      "metadata": {
        "id": "OGRwFUqrfsbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = Data(x=embed.weight, edge_index=torchgeom_graph.edge_index)\n",
        "print(data.x.shape)\n",
        "print(data.edge_index.shape)   #OK"
      ],
      "metadata": {
        "id": "p7t6bLT5nKhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate the GNN\n",
        "print(f'Building {model} model...')\n",
        "if model=='SAGEConv':\n",
        "  net = GraphSAGE(data, dim_embedding, hidden_dim, number_classes, dropout)      #sarebbe la mia classe che devo definire (fatto sopra)\n",
        "  #def cosi net = GraphSAGE(in_channels=dim_embedding, hidden_channels=dim_embedding, out_channels=num_classes)\n",
        "elif model == 'GNN':\n",
        "  #net = GCN(Conv)\n",
        "  print('ci va l altra')\n",
        "\n",
        "print(net)"
      ],
      "metadata": {
        "id": "z_XNGWQInWk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve known optimizer hypers\n",
        "opt_hypers = {\n",
        "    'lr': hypers.get('learning_rate', None)\n",
        "}\n",
        "\n",
        "# Get adjacency matrix for use in calculations\n",
        "adj_ = get_adjacency_matrix(nx_graph, TORCH_DEVICE, TORCH_DTYPE)\n",
        "\n",
        "# See minimal_utils.py for description. Constructs GNN and optimizer objects from given hypers.\n",
        "# Initializes embedding layer to use as initial model input\n",
        "#net, embed, optimizer gia def"
      ],
      "metadata": {
        "id": "urqq9TqSnWoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(adj_.shape)\n",
        "print(adj_)"
      ],
      "metadata": {
        "id": "PVsU3OHS6Z4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up Adam optimizer\n",
        "params = chain(net.parameters(), embed.parameters())\n",
        "\n",
        "print('Building ADAM-W optimizer...')\n",
        "optimizer = torch.optim.AdamW(params, **opt_hypers, weight_decay=1e-2)            #weight_decay = decadimento esponenziale che contiene overfitting\n",
        "#scheduler= torch.optim.lr_scheduler.StepLR(optimizer,step_size=100000,gamma=1.5)    #AGGIUNTA IL 18/10 #step_size, ogni quante epoche il lr diminuisce del 10%(gamma=0.1)\n",
        "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=500)\n",
        "\n",
        "\n",
        "print(optimizer)"
      ],
      "metadata": {
        "id": "vfuGGjr6oemV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function for graph-coloring loss\n",
        "def loss_func_mod(probs, adj_tensor):\n",
        "    \"\"\"\n",
        "    Function to compute cost value based on soft assignments (probabilities)\n",
        "\n",
        "    :param probs: Probability vector, of each node belonging to each class\n",
        "    :type probs: torch.tensor\n",
        "    :param adj_tensor: Adjacency matrix, containing internode weights\n",
        "    :type adj_tensor: torch.tensor\n",
        "    :return: Loss, given the current soft assignments (probabilities)\n",
        "    :rtype: float\n",
        "    \"\"\"\n",
        "\n",
        "    # Multiply probability vectors, then filter via elementwise application of adjacency matrix.\n",
        "    #  Divide by 2 to adjust for symmetry about the diagonal\n",
        "    loss_ = torch.mul(adj_tensor, (probs @ probs.T)).sum() / 2\n",
        "\n",
        "    return loss_      #sarebbe la mia energia di potts\n",
        "\n",
        "# helper function for custom loss according to Q matrix\n",
        "def loss_func_color_hard(coloring, nx_graph):\n",
        "    \"\"\"\n",
        "    Function to compute cost value based on color vector (0, 2, 1, 4, 1, ...)\n",
        "\n",
        "    :param coloring: Vector of class assignments (colors)\n",
        "    :type coloring: torch.tensor\n",
        "    :param nx_graph: Graph to evaluate classifications on\n",
        "    :type nx_graph: networkx.OrderedGraph  --> da me cambiato con DiGraph\n",
        "    :return: Cost of provided class assignments\n",
        "    :rtype: torch.tensor\n",
        "    \"\"\"\n",
        "\n",
        "    cost_ = 0\n",
        "    for (u, v) in nx_graph.edges:\n",
        "        cost_ += 1*(coloring[u] == coloring[v])*(u != v)     #1 if the two nodes have the same color and are not the same node\n",
        "\n",
        "    return cost_"
      ],
      "metadata": {
        "id": "zIegmMU9Ivq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(nx_graph.edges)"
      ],
      "metadata": {
        "id": "0xfBYsl_6nqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(nx_graph.number_of_edges())"
      ],
      "metadata": {
        "id": "yLqiwJEz612m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainCycle(seed=hypers['seed']):\n",
        "  # Ensure RNG seeds are reset each training run\n",
        "  #seed=hypers['seed']\n",
        "  print(f'Start training(): Setting seed to {seed}')\n",
        "  #seed=1\n",
        "  set_seed(seed)\n",
        "  number_epochs=int(5e4)\n",
        "  patience=500\n",
        "  tolerance=1e-3\n",
        "\n",
        "\n",
        "  # Tracking\n",
        "  best_cost = torch.tensor(float('Inf'))  # high initialization\n",
        "  best_loss = torch.tensor(float('Inf'))\n",
        "  best_coloring = None\n",
        "  best_model = net.state_dict()\n",
        "\n",
        "  # Early stopping to allow NN to train to near-completion\n",
        "  prev_loss = 1.  # initial loss value (arbitrary)\n",
        "  cnt = 0  # track number times early stopping is triggered\n",
        "  #count_stessicolori=0\n",
        "\n",
        "\n",
        "  #metto conto del tempo\n",
        "  t_start = time()\n",
        "  loss_vector_story=[]\n",
        "  hard_cost_vector_story=[]\n",
        "\n",
        "  count_stessicolori=0\n",
        "\n",
        "\n",
        "\n",
        "  # Training logic\n",
        "  for epoch in range(number_epochs):\n",
        "      # get soft prob assignments\n",
        "      logits = net(data)       #rispetto a prima net mi prende tutto il formato data\n",
        "\n",
        "      # apply softmax for normalization\n",
        "      probs = F.softmax(logits, dim=1)       #qua dovrebbe normalizzare\n",
        "      #print('probs=',probs)\n",
        "      #print(probs.shape)           #========esce 25x5 (sarebbero le 5 prob dei 5 colori per ogni nodo, poi devo prendere quella maggiore)\n",
        "\n",
        "      # get cost value with POTTS cost function\n",
        "      loss = loss_func_mod(probs, adj_)              #calcolo la loss con modello potts\n",
        "\n",
        "      # get cost based on current hard class assignments\n",
        "      # update cost if applicable\n",
        "      coloring = torch.argmax(probs, dim=1)\n",
        "      #print(coloring.shape)                             #questo é effettivamente il vettore dei colori di questa epoca (con 25 elementi che sono numeri da 0 a 4)\n",
        "      cost_hard = loss_func_color_hard(coloring, nx_graph)           #nodi diversi ma collegati e dello stesso colore\n",
        "\n",
        "      if cost_hard < best_cost:           #best_cost= il miglior cost_hard    #best_coloring=il coloring col miglior cost_hard\n",
        "          best_loss = loss\n",
        "          best_cost = cost_hard     #sarebbe sbaglio 'discreto'\n",
        "          best_coloring = coloring\n",
        "          best_model = net.state_dict()\n",
        "          #save_model(net,save_model_path, best_cost, best_loss, epoch)\n",
        "          #torch.save(net.state_dict(), 'SAGE_best_model_coloring_5X5.pth')                    #aggiunto stasera\n",
        "          #print(f'Model saved with best_cost: {best_cost:.4f}  and best_loss(soft loss): {best_loss:.4f} at the epoch: {epoch}')             #aggiunto stasera\n",
        "\n",
        "      # Early stopping check\n",
        "      # If loss increases or change in loss is too small, trigger\n",
        "      if (abs(loss - prev_loss) <= tolerance) | ((loss - prev_loss) > 0):\n",
        "          cnt += 1\n",
        "      else:\n",
        "          cnt = 0\n",
        "\n",
        "      #if (best_cost == cost_hard):\n",
        "      #    count_stessicolori+=1\n",
        "      #else:\n",
        "      #    count_stessicolori=0\n",
        "\n",
        "      # update loss tracking\n",
        "      prev_loss = loss\n",
        "\n",
        "      loss_vector_story.append(loss.item())               #mi dovrebbe dare la loss nelle epoche (ogni 1000)\n",
        "      hard_cost_vector_story.append(cost_hard.item())\n",
        "\n",
        "      if cnt >= patience:\n",
        "          print(f'Stopping early on epoch {epoch}. Patience count: {cnt}')\n",
        "          break\n",
        "\n",
        "      #if count_stessicolori >= patience:\n",
        "      #    optimizer = torch.optim.AdamW(params, **opt_hypers, weight_decay=1e-1)\n",
        "      #    print()\n",
        "\n",
        "      # run optimization with backpropagation\n",
        "      optimizer.zero_grad()  # clear gradient for step\n",
        "      loss.backward()  # calculate gradient through compute graph\n",
        "      optimizer.step()  # take step, update weights\n",
        "      #scheduler.step()\n",
        "\n",
        "      # tracking: print intermediate loss at regular interval\n",
        "      if epoch % 1000 == 0:\n",
        "          print('Epoch %d | Soft Loss: %.5f' % (epoch, loss.item()))\n",
        "          print('Epoch %d | Discrete Cost: %.2f' % (epoch, cost_hard.item()))\n",
        "\n",
        "  # Print final loss\n",
        "  print('Epoch %d | Final loss: %.5f' % (epoch, loss.item()))\n",
        "  print('Epoch %d | Lowest discrete cost: %.2f' % (epoch, best_cost))\n",
        "\n",
        "  # Final coloring\n",
        "  final_loss = loss\n",
        "  final_coloring = torch.argmax(probs, 1)\n",
        "  print(f'Final coloring: {final_coloring}, soft loss: {final_loss}')\n",
        "  print(f'Best coloring: {best_coloring}, soft loss: {best_loss}')\n",
        "\n",
        "  #conto finale del tempo\n",
        "  runtime_gnn = round(time() - t_start, 4)\n",
        "  # report results\n",
        "  print(f'GNN runtime: {runtime_gnn}s')\n",
        "\n",
        "  return best_model, loss_vector_story, hard_cost_vector_story, best_coloring"
      ],
      "metadata": {
        "id": "DZy_P_XgwycX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.to(TORCH_DEVICE)\n",
        "data.to(TORCH_DEVICE) #non so quanto sia utile"
      ],
      "metadata": {
        "id": "oWXT-iGWbxv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, loss_vector_story, hard_cost_vector_story, best_coloring = trainCycle()"
      ],
      "metadata": {
        "id": "cLrd5aqyVBZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_vector_story_array=np.array(loss_vector_story)\n",
        "hard_cost_vector_story_array= np.array(hard_cost_vector_story)\n",
        "\n",
        "print(loss_vector_story_array.shape)"
      ],
      "metadata": {
        "id": "j7I8DXIfxVZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Traccio il grafico della loss\n",
        "from matplotlib import pyplot as plt\n",
        "import math\n",
        "#loss_vector_story_array= np.array(loss_vector_story)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range((loss_vector_story_array.shape[0])), loss_vector_story_array, label='Loss')\n",
        "plt.title('Loss durante l\\'addestramento con lr:0.0001 e weight decay 0.01')\n",
        "plt.xlabel('Epoche')\n",
        "plt.ylabel('Loss')\n",
        "plt.yticks(range(0, math.floor(max(loss_vector_story)) + 1, 25))\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Traccio il grafico della loss nelle prime 500 epoche\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range((loss_vector_story_array.shape[0])), loss_vector_story_array, label='Loss')\n",
        "plt.title('Loss durante l\\'addestramento per le prime 500 epoche')\n",
        "plt.xlabel('Epoche')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlim(0,500)\n",
        "plt.yticks(range(0, math.floor(max(loss_vector_story)) + 1, 25))              #prendo il massimo di questa lista(loss_vector_story) e lo rendo un numero\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wMW90X52xVcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Traccia il grafico della loss\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range((hard_cost_vector_story_array.shape[0])), hard_cost_vector_story, label='Loss')\n",
        "plt.title('Costo discreto durante l\\'addestramento con lr:0.0001 e weight decay 0.01')\n",
        "plt.xlabel('Epoche')\n",
        "plt.ylabel('Costo discreto')\n",
        "plt.yticks(range(0, max(hard_cost_vector_story) + 10, 25))\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range((hard_cost_vector_story_array.shape[0])), hard_cost_vector_story, label='Loss')\n",
        "plt.title('Costo discreto durante l\\'addestramento per le prime 500 epoche')\n",
        "plt.xlabel('Epoche')\n",
        "plt.ylabel('Costo discreto')\n",
        "plt.yticks(range(0, max(hard_cost_vector_story) + 10, 25))\n",
        "plt.xlim(0,500)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "t1vljD0_xVeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize result\n",
        "color_dict = {\n",
        "    0: \"blue\",      # blu\n",
        "    1: \"orange\",    # arancione\n",
        "    2: \"green\",     # verde\n",
        "    3: \"red\",       # rosso\n",
        "    4: \"purple\",    # viola\n",
        "    5: \"brown\",     # marrone\n",
        "    6: \"pink\",      # rosa\n",
        "    7: \"gray\",      # grigio\n",
        "    8: \"olive\",     # giallo oliva\n",
        "    9: \"cyan\",      # ciano\n",
        "}\n",
        "color_map = np.vectorize(color_dict.get)(best_coloring.cpu())\n",
        "nx.draw(nx_graph, pos, with_labels=False, node_color=color_map)"
      ],
      "metadata": {
        "id": "1ky8MQaoxVhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PROVO A FARMI PLOTTARE I LINK SBAGLIATI IN ROSSO\n",
        "\n",
        "#color_dict = {0:'orange', 1:'lightblue', 2:'purple', 3:'red', 4:'lightgreen',5:'green',6:'yellow',7:'pink'}\n",
        "color_map = np.vectorize(color_dict.get)(best_coloring.cpu())\n",
        "edge_color_map = ['red' if best_coloring[u] == best_coloring[v] else 'black' for u, v in nx_graph.edges()]\n",
        "\n",
        "wrong_edges=[(u, v) for u, v in nx_graph.edges() if best_coloring[u] == best_coloring[v]]  # Archi rossi=archi sbagliati\n",
        "\n",
        "nx.draw(nx_graph, pos, with_labels=False, node_color=color_map,edge_color=edge_color_map)\n",
        "nx.draw_networkx_edges(nx_graph, pos, edgelist=wrong_edges, edge_color='red')      #me le plotta sopra le altre"
      ],
      "metadata": {
        "id": "dHxVCB7_dTtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#definisco funzione che mi calcola errore come:\n",
        "#numero di edges sbagliate con potts/num link\n",
        "def err_gen(coloring):\n",
        "  num_link = torchgeom_graph.edge_index.shape[1]\n",
        "  cost_discreto = loss_func_color_hard(coloring, nx_graph)\n",
        "  eps=cost_discreto/num_link               #dovrebbe considerare che il grafo é indiretto sia nel costo discreto che nel numero dei link\n",
        "\n",
        "  return num_link, cost_discreto, eps"
      ],
      "metadata": {
        "id": "fCuCp6fKqPz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "err = err_gen(best_coloring)\n",
        "print(f'Numero di link: {err[0]}   Hard cost: {err[1]}')\n",
        "print(f'errore = {err[2] * 100:.3f}.%')"
      ],
      "metadata": {
        "id": "Rgq-I9PGqP4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Addestro più reti\n",
        "\n",
        "loss_collection = []\n",
        "cost_collection = []\n",
        "err_collection = []\n",
        "\n",
        "NUM_MODELLI = 10\n",
        "\n",
        "for j in range(NUM_MODELLI):\n",
        "    net = GraphSAGE(data, dim_embedding, hidden_dim, number_classes, dropout)\n",
        "    net.to(TORCH_DEVICE)\n",
        "    _, loss_vector_story, hard_cost_vector_story, best_coloring = trainCycle(j)\n",
        "    loss_collection.append(loss_vector_story)\n",
        "    cost_collection.append(hard_cost_vector_story)\n",
        "    err_collection.append(err_gen(best_coloring))"
      ],
      "metadata": {
        "id": "-TU9B4HhqP8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (j, story) in enumerate(loss_collection):\n",
        "  # Traccio il grafico della loss\n",
        "  from matplotlib import pyplot as plt\n",
        "  import math\n",
        "  #loss_vector_story_array= np.array(loss_vector_story)\n",
        "\n",
        "  plt.figure(figsize=(10, 5))\n",
        "  plt.plot(range((story.shape[0])), story, label='Loss')\n",
        "  plt.title(f'[{j}] Loss durante l\\'addestramento con lr:0.0001 e weight decay 0.01')\n",
        "  plt.xlabel('Epoche')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.yticks(range(0, math.floor(max(story)) + 1, 10))\n",
        "  plt.legend()\n",
        "  plt.grid()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "uMOBAu1aaXw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (j, story) in enumerate(cost_collection):\n",
        "  # Traccia il grafico della loss\n",
        "  plt.figure(figsize=(10, 5))\n",
        "  plt.plot(range((story.shape[0])), story, label='Loss')\n",
        "  plt.title(f'[{j}] Costo discreto durante l\\'addestramento con lr:0.0001 e weight decay 0.01')\n",
        "  plt.xlabel('Epoche')\n",
        "  plt.ylabel('Costo discreto')\n",
        "  plt.yticks(range(0, max(story) + 10, 10))\n",
        "  plt.legend()\n",
        "  plt.grid()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "OV7lCtHuageX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (j, err) in enumerate(err_collection):\n",
        "  print(f'[{j}] Numero di link: {err[0]}   Hard cost: {err[1]}')\n",
        "  print(f'[{j}] errore = {err[2] * 100:.3f}.%')"
      ],
      "metadata": {
        "id": "DUgpbb8Carkg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}